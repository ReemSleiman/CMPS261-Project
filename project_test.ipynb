{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "This notebook is meant to test the best model for our project Food Item Recognition from Images.\n",
    "\n",
    "Please download the model from our github repository: https://github.com/ReemSleiman/CMPS261-Project.git\n",
    "\n",
    "In the models folder, you will find several saved models. The best one is saved under name: \"model_before_tuning.h5\"\n",
    "\n",
    "Download the model and save it in the same directory of this notebook.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Part 1: Data preprocessing "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 114,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import numpy as np\n",
    "from tensorflow.keras.preprocessing.image import img_to_array, load_img\n",
    "from tensorflow.keras.utils import to_categorical"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Assuming that the 'test' folder is within a 'data' folder and it contains subfolders named after the class index (1 to 9), and each subfolder contains images corresponding to that class, we'll load images from each subfolder, extract their labels based on the subfolder name, and preprocess them for testing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 115,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Preprocess the raw test data with subfolders and one-hot encode labels\n",
    "def preprocess_test_data(test_data_folder, img_size=(150, 150)):\n",
    "    test_images = []\n",
    "    test_labels = []\n",
    "\n",
    "    # Loop through each class subfolder\n",
    "    for class_name in os.listdir(test_data_folder):\n",
    "        class_folder = os.path.join(test_data_folder, class_name)\n",
    "        if os.path.isdir(class_folder):\n",
    "            class_label = int(class_name) - 1  # Extract class label from folder name, and subtract 1 to make it zero-indexed\n",
    "\n",
    "            # Loop through each image in the class subfolder\n",
    "            for img_name in os.listdir(class_folder):\n",
    "                img_path = os.path.join(class_folder, img_name)\n",
    "                # Load and resize the image\n",
    "                img = load_img(img_path, target_size=img_size)\n",
    "                # Convert image to array and normalize pixel values\n",
    "                img_array = img_to_array(img) / 255.0\n",
    "                # Append image array and corresponding label to lists\n",
    "                test_images.append(img_array)\n",
    "                test_labels.append(class_label)\n",
    "\n",
    "    # Convert test_labels to one-hot encoded format\n",
    "    test_labels = to_categorical(test_labels, num_classes=9)\n",
    "\n",
    "    return np.array(test_images), np.array(test_labels)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 116,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Define the path to the raw test data folder\n",
    "raw_test_data_folder = os.path.join(os.getcwd(), \"data\", \"test\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 117,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Preprocess the raw test data\n",
    "test_images, test_labels = preprocess_test_data(raw_test_data_folder)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Part 2: Loading the model "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load the trained model\n",
    "from tensorflow.keras.models import load_model\n",
    "\n",
    "model_path = \"model_before_tuning.h5\"\n",
    "model = load_model(model_path)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 119,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Compile the model\n",
    "model.compile(optimizer='adam',\n",
    "              loss='categorical_crossentropy',\n",
    "              metrics=['accuracy'])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Part 3: Testing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 120,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[1m25/25\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 91ms/step - accuracy: 0.8384 - loss: 0.4814\n",
      "Test Loss: 0.6745206117630005, Test Accuracy: 0.7710220217704773\n"
     ]
    }
   ],
   "source": [
    "# Evaluate the model on the preprocessed test data\n",
    "test_loss, test_accuracy = model.evaluate(test_images, test_labels)\n",
    "print(f\"Test Loss: {test_loss}, Test Accuracy: {test_accuracy}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Part 4: Testing for an image from the internet"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 121,
   "metadata": {},
   "outputs": [],
   "source": [
    "import requests\n",
    "from PIL import Image\n",
    "from io import BytesIO"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 122,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Function to preprocess a single image from the internet\n",
    "def preprocess_image_from_url(image_url, img_size=(150, 150)):\n",
    "    response = requests.get(image_url)\n",
    "    image = Image.open(BytesIO(response.content))\n",
    "    image = image.resize(img_size)\n",
    "    img_array = np.array(image) / 255.0  # Normalize pixel values\n",
    "    img_array = np.expand_dims(img_array, axis=0)  # Add batch dimension\n",
    "    return img_array"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 123,
   "metadata": {},
   "outputs": [],
   "source": [
    "# URL of the image you want to test, replace with the desired image URL \n",
    "\n",
    "# Example: image url to a bottle\n",
    "image_url = \"https://i5.walmartimages.com/asr/83568193-2418-40f0-8367-4fd80481e2f8_1.fc5284020d9e9b9bcd45d777a9e62bb5.jpeg\" "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 124,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 91ms/step\n",
      "Predicted Class: bottle\n"
     ]
    }
   ],
   "source": [
    "# Preprocess the image\n",
    "test_image = preprocess_image_from_url(image_url)\n",
    "\n",
    "# Use the loaded model to make predictions on the preprocessed image\n",
    "predictions = model.predict(test_image)\n",
    "predicted_class = np.argmax(predictions[0])\n",
    "\n",
    "# Map predicted class index to class label (assuming class labels are 1 to 9)\n",
    "class_labels = [\"bottle\", \"basket\", \"food\", \"cup\", \"jar\", \"can\", \"dish\", \"mug\", \"glass\"]\n",
    "predicted_label = class_labels[predicted_class]\n",
    "\n",
    "print(\"Predicted Class:\", predicted_label)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
