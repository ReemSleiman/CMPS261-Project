{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Introduction:\n",
    "1. Data Preprrocessing techniques:\n",
    "    a. image resize\n",
    "    b. Normalization \n",
    "    c. Data Augmentation (Example: Horizontal Flipping, rotation, scaling )\n",
    "    d. Histogram Equalization\n",
    "    e. Data Cleaning (Example: Removing images with low contrast)\n",
    "    f. Noise Reduction (bluring and denoising)\n",
    "    g. Splitting the Dataset (Example: 80-10-10 split)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Lets split the data first into training, validation and testing using the 70%, 15%, 15% respectively."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import shutil\n",
    "import random\n",
    "\n",
    "# Get the current working directory\n",
    "cwd = os.getcwd()\n",
    "\n",
    "# Define paths relative to the working directory\n",
    "data_dirOuter = os.path.join(cwd, 'data')\n",
    "data_dir = os.path.join(data_dirOuter, 'data')  # data folder that contains all the images \n",
    "train_dir = os.path.join(data_dirOuter, 'train')  # Train directory inside the first data folder\n",
    "val_dir = os.path.join(data_dirOuter, 'val')      # Validation directory inside the first data folder\n",
    "test_dir = os.path.join(data_dirOuter, 'test')\n",
    "\n",
    "# Define the split ratios\n",
    "train_ratio = 0.7\n",
    "val_ratio = 0.15\n",
    "test_ratio = 0.15\n",
    "\n",
    "# Create directories for train, val, and test sets\n",
    "os.makedirs(train_dir, exist_ok=True)\n",
    "os.makedirs(val_dir, exist_ok=True)\n",
    "os.makedirs(test_dir, exist_ok=True)\n",
    "\n",
    "# Loop through each class folder\n",
    "for class_name in os.listdir(data_dir):\n",
    "    class_path = os.path.join(data_dir, class_name)\n",
    "    if os.path.isdir(class_path):\n",
    "        images = os.listdir(class_path)\n",
    "        random.shuffle(images)\n",
    "        \n",
    "        # Calculate split indices\n",
    "        train_split = int(train_ratio * len(images))\n",
    "        val_split = int((train_ratio + val_ratio) * len(images))\n",
    "        \n",
    "        # Move images to respective directories\n",
    "        for i, image in enumerate(images):\n",
    "            src_path = os.path.join(class_path, image)\n",
    "            if i < train_split:\n",
    "                dst_dir = os.path.join(train_dir, class_name)\n",
    "            elif i < val_split:\n",
    "                dst_dir = os.path.join(val_dir, class_name)\n",
    "            else:\n",
    "                dst_dir = os.path.join(test_dir, class_name)\n",
    "            \n",
    "            os.makedirs(dst_dir, exist_ok=True)\n",
    "            shutil.copy(src_path, dst_dir)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "now we are going to use CNN for classifying the images "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import tensorflow as tf\n",
    "from tensorflow.keras import datasets, layers, models\n",
    "import matplotlib.pyplot as plt\n",
    "import numpy as np"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Load the data "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "ename": "ValueError",
     "evalue": "setting an array element with a sequence. The requested array has an inhomogeneous shape after 1 dimensions. The detected shape was (3586,) + inhomogeneous part.",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mValueError\u001b[0m                                Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[12], line 34\u001b[0m\n\u001b[0;32m     30\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m np\u001b[38;5;241m.\u001b[39marray(X), np\u001b[38;5;241m.\u001b[39marray(y)\n\u001b[0;32m     33\u001b[0m \u001b[38;5;66;03m# Load the data\u001b[39;00m\n\u001b[1;32m---> 34\u001b[0m X_train, y_train \u001b[38;5;241m=\u001b[39m \u001b[43mload_data\u001b[49m\u001b[43m(\u001b[49m\u001b[43mtrain_dir\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m     35\u001b[0m X_val, y_val \u001b[38;5;241m=\u001b[39m load_data(val_dir)\n\u001b[0;32m     36\u001b[0m X_test, y_test \u001b[38;5;241m=\u001b[39m load_data(test_dir)\n",
      "Cell \u001b[1;32mIn[12], line 30\u001b[0m, in \u001b[0;36mload_data\u001b[1;34m(data_dir)\u001b[0m\n\u001b[0;32m     28\u001b[0m             X\u001b[38;5;241m.\u001b[39mappend(image)\n\u001b[0;32m     29\u001b[0m             y\u001b[38;5;241m.\u001b[39mappend(class_id \u001b[38;5;241m-\u001b[39m \u001b[38;5;241m1\u001b[39m)  \u001b[38;5;66;03m# Subtract 1 to convert class_id to zero-based index\u001b[39;00m\n\u001b[1;32m---> 30\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mnp\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43marray\u001b[49m\u001b[43m(\u001b[49m\u001b[43mX\u001b[49m\u001b[43m)\u001b[49m, np\u001b[38;5;241m.\u001b[39marray(y)\n",
      "\u001b[1;31mValueError\u001b[0m: setting an array element with a sequence. The requested array has an inhomogeneous shape after 1 dimensions. The detected shape was (3586,) + inhomogeneous part."
     ]
    }
   ],
   "source": [
    "import os\n",
    "import shutil\n",
    "import random\n",
    "from tensorflow.keras.models import Sequential\n",
    "from tensorflow.keras.layers import Conv2D, MaxPooling2D, Flatten, Dense\n",
    "from tensorflow.keras.optimizers import Adam\n",
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "\n",
    "cwd = os.getcwd()\n",
    "data_dirOuter = os.path.join(cwd, 'data')\n",
    "train_dir = os.path.join(data_dirOuter, 'train')\n",
    "val_dir = os.path.join(data_dirOuter, 'val')\n",
    "test_dir = os.path.join(data_dirOuter, 'test')\n",
    "\n",
    "# Define the classes\n",
    "classes = [\"bottle\", \"basket\", \"food\", \"cup\", \"jar\", \"can\", \"dish\", \"mug\", \"glass\"]\n",
    "\n",
    "from PIL import Image\n",
    "\n",
    "def load_data(data_dir, image_size=(32, 32)):\n",
    "    X = []\n",
    "    y = []\n",
    "    for class_id, class_dir in enumerate(sorted(os.listdir(data_dir)), 1):\n",
    "        if os.path.isdir(os.path.join(data_dir, class_dir)):\n",
    "            for image_name in os.listdir(os.path.join(data_dir, class_dir)):\n",
    "                image_path = os.path.join(data_dir, class_dir, image_name)\n",
    "                image = Image.open(image_path)\n",
    "                image = image.resize(image_size)\n",
    "                image = np.array(image) / 255.0  # Normalize the image\n",
    "                X.append(image)\n",
    "                y.append(class_id - 1)  # Subtract 1 to convert class_id to zero-based index\n",
    "    return np.array(X), np.array(y)\n",
    "\n",
    "\n",
    "# Load the data\n",
    "X_train, y_train = load_data(train_dir)\n",
    "X_val, y_val = load_data(val_dir)\n",
    "X_test, y_test = load_data(test_dir)\n",
    "\n",
    "# Normalize the images\n",
    "X_train = X_train / 255.0\n",
    "X_val = X_val / 255.0\n",
    "X_test = X_test / 255.0\n",
    "\n",
    "# Define and compile the model\n",
    "cnn = Sequential([\n",
    "    Conv2D(filters=32, kernel_size=(3, 3), activation='relu', input_shape=(X_train.shape[1:])),\n",
    "    MaxPooling2D((2, 2)),\n",
    "    Conv2D(filters=64, kernel_size=(3, 3), activation='relu'),\n",
    "    MaxPooling2D((2, 2)),\n",
    "    Flatten(),\n",
    "    Dense(64, activation='relu'),\n",
    "    Dense(len(classes), activation='softmax')  # Use len(classes) as the number of output units\n",
    "])\n",
    "\n",
    "cnn.compile(optimizer=Adam(),\n",
    "              loss='sparse_categorical_crossentropy',\n",
    "              metrics=['accuracy'])\n",
    "\n",
    "# Train the model\n",
    "history = cnn.fit(X_train, y_train, epochs=10, validation_data=(X_val, y_val))\n",
    "\n",
    "# Evaluate the model\n",
    "loss, accuracy = cnn.evaluate(X_test, y_test)\n",
    "print(\"Test Loss:\", loss)\n",
    "print(\"Test Accuracy:\", accuracy)\n",
    "\n",
    "# Plot training history\n",
    "plt.plot(history.history['accuracy'], label='accuracy')\n",
    "plt.plot(history.history['val_accuracy'], label = 'val_accuracy')\n",
    "plt.xlabel('Epoch')\n",
    "plt.ylabel('Accuracy')\n",
    "plt.legend(loc='lower right')\n",
    "plt.show()\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
